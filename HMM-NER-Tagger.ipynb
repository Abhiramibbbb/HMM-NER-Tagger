{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13OCk3U_I7-_",
        "outputId": "83a59486-9a6c-401b-b920-dbe17e935ebe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
            "https://github.com/hmmlearn/hmmlearn/issues/335\n",
            "https://github.com/hmmlearn/hmmlearn/issues/340\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Encoding: ascii\n",
            "Precision: 0.751, Recall: 0.818, F1-score: 0.783\n",
            "Test Sentence: ['Ibuprofen', 'is', 'used', 'to', 'reduce', 'inflammation', '.']\n",
            "Predicted Labels: ['D', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import hmmlearn.hmm as hmm\n",
        "from collections import Counter\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import chardet\n",
        "\n",
        "\n",
        "\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        raw_data = f.read(10000)\n",
        "        detected_encoding = chardet.detect(raw_data)[\"encoding\"]\n",
        "        return detected_encoding\n",
        "\n",
        "\n",
        "def load_data(file_path, encoding=None):\n",
        "    if encoding is None:\n",
        "        encoding = detect_encoding(file_path)\n",
        "        print(f\"Detected Encoding: {encoding}\")\n",
        "\n",
        "    sentences, labels = [], []\n",
        "    sentence, label_seq = [], []\n",
        "\n",
        "    with open(file_path, 'r', encoding=encoding, errors=\"replace\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 2:\n",
        "                    token, label = parts[0], parts[-1]\n",
        "                    sentence.append(token)\n",
        "                    label_seq.append(label)\n",
        "            else:\n",
        "                if sentence:\n",
        "                    sentences.append(sentence)\n",
        "                    labels.append(label_seq)\n",
        "                    sentence, label_seq = [], []\n",
        "\n",
        "    if sentence:\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label_seq)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "\n",
        "def create_vocab(sentences):\n",
        "    word_counts = Counter(word for sent in sentences for word in sent)\n",
        "    vocab = {word for word, count in word_counts.items() if count > 1}\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocab, start=1)}\n",
        "    word2idx[\"UNK\"] = 0\n",
        "    return word2idx\n",
        "\n",
        "\n",
        "\n",
        "def create_label_dict(labels):\n",
        "    unique_labels = sorted(set(label for lbl_seq in labels for label in lbl_seq))\n",
        "    label2idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    idx2label = {idx: label for label, idx in label2idx.items()}\n",
        "    return label2idx, idx2label\n",
        "\n",
        "\n",
        "def prepare_sequences(sentences, labels, word2idx, label2idx):\n",
        "    X = [[word2idx.get(word, 0) for word in sent] for sent in sentences]\n",
        "    Y = [[label2idx[label] for label in lbl_seq] for lbl_seq in labels]\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def train_hmm(X, Y, n_states):\n",
        "    lengths = [len(seq) for seq in X]\n",
        "    X_flat = np.concatenate(X).reshape(-1, 1)\n",
        "\n",
        "    model = hmm.MultinomialHMM(n_components=n_states, n_iter=100, tol=0.01)\n",
        "    model.fit(X_flat, lengths)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def predict_hmm(model, X):\n",
        "    predictions = []\n",
        "    for seq in X:\n",
        "        seq = np.array(seq).reshape(-1, 1)\n",
        "        preds = model.predict(seq)\n",
        "        predictions.append(preds)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(predictions, Y, idx2label):\n",
        "    y_true = np.concatenate(Y)\n",
        "    y_pred = np.concatenate(predictions)\n",
        "    y_true = [idx2label[idx] for idx in y_true]\n",
        "    y_pred = [idx2label[idx] for idx in y_pred]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}\")\n",
        "\n",
        "\n",
        "\n",
        "def predict_new_sentence(model, sentence, word2idx, idx2label):\n",
        "    sentence_idx = [word2idx.get(word, 0) for word in sentence]\n",
        "    sentence_idx = np.array(sentence_idx).reshape(-1, 1)\n",
        "    predictions = model.predict(sentence_idx)\n",
        "    return [idx2label[idx] for idx in predictions]\n",
        "\n",
        "\n",
        "\n",
        "file_path = r\"/content/ner.txt\"\n",
        "\n",
        "\n",
        "sentences, labels = load_data(file_path)\n",
        "\n",
        "\n",
        "word2idx = create_vocab(sentences)\n",
        "label2idx, idx2label = create_label_dict(labels)\n",
        "\n",
        "\n",
        "X, Y = prepare_sequences(sentences, labels, word2idx, label2idx)\n",
        "\n",
        "\n",
        "n_states = len(label2idx)\n",
        "hmm_model = train_hmm(X, Y, n_states)\n",
        "\n",
        "\n",
        "y_pred = predict_hmm(hmm_model, X)\n",
        "evaluate(y_pred, Y, idx2label)\n",
        "\n",
        "test_sentence = [\"Ibuprofen\", \"is\", \"used\", \"to\", \"reduce\", \"inflammation\", \".\"]\n",
        "predicted_labels = predict_new_sentence(hmm_model, test_sentence, word2idx, idx2label)\n",
        "\n",
        "print(\"Test Sentence:\", test_sentence)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NzrEKLPLACK"
      },
      "source": [
        "The HMM model prefers to predict \"O\" for the majority of tokens because of the dataset's notable class imbalance, where the label \"O\" is highly popular.  This happens because the high frequency of \"O\" has a significant impact on the predicted probabilities.  In order to enhance performance and attain more precise forecasts for labels such as \"T\" and \"D,\" it is imperative to address this imbalance.  To guarantee a more representative learning process, this can be accomplished by balancing the dataset, using methods like smoothing, re-weighting, or improving the feature set.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
